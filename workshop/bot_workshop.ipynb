{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Basic bot](#basic-bot)\n",
    "3. [Open AI bot](#intelligent-bot)\n",
    "4. [Understanding why Open AI + LangChain](#optional-understanding-why-openai--langchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "**User Interaction Demo**\n",
    "\n",
    "In this demonstration, you'll create the first iteration of your interactive chatbot, designed to enhance your workshop experience. The bot will initiate a conversation paving the way for exploration into various interaction methods.\n",
    "\n",
    "Let's dive in:\n",
    "\n",
    "1. **Welcome to the Chatbot Workshop!**\n",
    "   - The bot will greet you and set the stage for our interactive session.\n",
    "2. **Workshop Check-In: Share Your Thoughts**\n",
    "   - The bot will prompt you to share your thoughts on the workshop and give you different options. Select the one that adjust better to you and explore the different ways your chatbot can respond.\n",
    "3. **Dynamic Responses**\n",
    "   - Discover how the bot adapts its replies based on your input. Whether you're finding the workshop excellent, facing challenges, or have other thoughts, the bot is ready to engage.\n",
    "4. **Good bye Responses**\n",
    "   - Once you're done, say good bye to the bot and it will reply to you!\n",
    "\n",
    "This interactive demo serves as a glimpse into the versatility of our chatbot, showcasing its ability to dynamically respond to user input. Enjoy the exploration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic bot\n",
    "Let's break down its key functionalities so it is easier to follow:\n",
    "\n",
    "1. **Welcome and Goodbye Commands:**\n",
    "   - The `send_welcome` function responds to the \"/start\" and \"/hi\" commands with a welcome message and prompts the user for their name. It then registers the `process_name_step` function to handle the next step.\n",
    "   - The `send_goodbye` function responds to \"/end\" and \"/bye\" commands with a goodbye message.\n",
    "\n",
    "```python\n",
    "@bot.message_handler(commands=['start', 'hi'])\n",
    "def send_welcome(message: telebot.types.Message):\n",
    "    # ... (explained above)\n",
    "\n",
    "@bot.message_handler(commands=['end', 'bye'])\n",
    "def send_goodbye(message: telebot.types.Message):\n",
    "    # ... (explained above)\n",
    "```\n",
    "\n",
    "2. **User Name Input Processing:**\n",
    "   - The `process_name_step` function processes the user's name input, creates a User object, and stores it in the `user_dict` dictionary. It then sets up a reply message asking about the workshop status and registers the `process_workshop_step` function to handle the next step.\n",
    "\n",
    "```python\n",
    "def process_name_step(message: telebot.types.Message):\n",
    "    # ... (explained above)\n",
    "```\n",
    "\n",
    "3. **Workshop Status Input Processing:**\n",
    "   - The `process_workshop_step` function processes the user's workshop status input and responds accordingly based on the chosen option. It also prompts the user to send different types of files and continue the demo.\n",
    "  \n",
    "```python\n",
    "def process_workshop_step(message: telebot.types.Message):\n",
    "    # ... (explained above)\n",
    "```\n",
    "\n",
    "4. **Detecting Message Content Type:**\n",
    "   - The `detects_message_content_type` function detects and replies to the type of content the user sends, including text, audio, document, photo, sticker, video, voice, location, and contact.\n",
    "\n",
    "```python\n",
    "@bot.message_handler(content_types=['text', 'audio', 'document', 'photo', 'sticker', 'video', 'voice', 'location', 'contact'])\n",
    "def detects_message_content_type(message):\n",
    "    # ... (explained above)\n",
    "```\n",
    "\n",
    "Overall, this script sets up a basic interactive chatbot that welcomes users, gathers information about the workshop, and handles various types of user inputs. It's a foundation that can be expanded upon for more complex interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT_TOKEN = \"<your-bot-token>\"\n",
    "bot = telebot.TeleBot(BOT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_dict = {}\n",
    "\n",
    "class User:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.talk_status = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['start', 'hi'])\n",
    "def send_welcome(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Respond to the '/start' and '/hi' commands with a welcome message.\n",
    "\n",
    "    Args:\n",
    "        message (telebot.types.Message): The message object representing the user's command.\n",
    "    \"\"\"\n",
    "    welcome_message = \"<the-welcome-message-you-want-your-bot-to-say>, what's your name?\"\n",
    "    bot.reply_to(message, welcome_message)\n",
    "    bot.register_next_step_handler(message, process_name_step)\n",
    "\n",
    "\n",
    "@bot.message_handler(commands=['end', 'bye'])\n",
    "def send_goodbye(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Respond to the '/end' and '/bye' commands with a welcome message.\n",
    "\n",
    "    Args:\n",
    "        message (telebot.types.Message): The message object representing the user's command.\n",
    "    \"\"\"\n",
    "    goodbye_message = \"<the-good-bye-message-you-want-your-bot-to-say>\"\n",
    "    bot.reply_to(message, goodbye_message)\n",
    "\n",
    "\n",
    "def process_name_step(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Process the user's name input and set up the next step.\n",
    "\n",
    "    Args:\n",
    "        message (Message): The user's message.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chat_id = message.chat.id\n",
    "        name = message.text\n",
    "        user = User(name)\n",
    "        user_dict[chat_id] = user\n",
    "\n",
    "        markup = telebot.types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "        markup.add('<option-1>', '<option-2>', '<option-3>')\n",
    "\n",
    "        reply_message = f\"Hey, {name}! How's the workshop going?\"\n",
    "        msg = bot.reply_to(message, reply_message, reply_markup=markup)\n",
    "\n",
    "        bot.register_next_step_handler(msg, process_workshop_step)\n",
    "    except Exception as e:\n",
    "        bot.reply_to(message, \"Oopsie, there's been a problem! Let your instructors know so they can help you\")\n",
    "\n",
    "def process_workshop_step(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Process the user's talk status input and respond accordingly.\n",
    "\n",
    "    Args:\n",
    "        message (Message): The user's message.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chat_id = message.chat.id\n",
    "        workshop_status = message.text\n",
    "        user = user_dict.get(chat_id)\n",
    "\n",
    "        if user:\n",
    "            if workshop_status=='<option-1>':\n",
    "                msg = bot.send_message(\n",
    "                    chat_id, f\"<The-message-you-want-to-send-your-user-if-they-chose-option-1>\")\n",
    "            elif workshop_status=='<option-2>':\n",
    "                msg = bot.send_message(\n",
    "                    chat_id, f\"<The-message-you-want-to-send-your-user-if-they-chose-option-2>\")\n",
    "            elif workshop_status=='<option-3>':\n",
    "                msg = bot.send_message(\n",
    "                    chat_id, f\"<The-message-you-want-to-send-your-user-if-they-chose-option-3>\")\n",
    "            bot.send_message(chat_id, \"Let's see now how good I am at detecting different content types, send me different type of files try with: audios, document, photo, sticker, video, voice, location or contact\")\n",
    "\n",
    "    except Exception as e:\n",
    "        bot.reply_to(message, \"Oopsie, there's been a problem! Let your instructors know so they can help you\")\n",
    "\n",
    "@bot.message_handler(content_types=['audio', 'document', 'photo', 'sticker', 'video', 'voice', 'location', 'contact'])\n",
    "def detects_message_content_type(message):\n",
    "    \"\"\"\n",
    "    Detects imessage_content_type. The content type content_type can be one of the following strings:\n",
    "    text, audio, document, photo, sticker, video, video_note, voice, location, contact...\n",
    "\n",
    "    Args:\n",
    "        message (telebot.types.Message): The message object sent by the user.\n",
    "    \"\"\"\n",
    "    content_type = message.content_type\n",
    "    bot.reply_to(message, f\"You've sent me a file of type: {content_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.enable_save_next_step_handlers(delay=2)\n",
    "bot.load_next_step_handlers()\n",
    "bot.infinity_polling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the above cell:\n",
    "\n",
    "1. `bot.enable_save_next_step_handlers(delay=2)`: This line configures the bot to save the next step handlers. In the context of a Telegram bot, a \"step\" usually refers to a specific stage or part of a conversation. The `enable_save_next_step_handlers` method is used to enable the saving of these next step handlers, and the `delay=2` parameter might indicate a delay of 2 seconds before saving.\n",
    "\n",
    "2. `bot.load_next_step_handlers()`: This line is loading the saved next step handlers. After enabling the saving in the previous line, this line loads the handlers. Next step handlers are used to manage conversations in a more organized way.\n",
    "\n",
    "3. `bot.infinity_polling()`: This line starts the bot with long polling. In the context of a Telegram bot, long polling is a way for the bot to continuously check for updates from the Telegram server and respond to them. The `infinity_polling` method indicates that the bot will keep polling indefinitely.\n",
    "\n",
    "You can now test your bot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interrupt please the execution of the notebook to create a new bot using Open AI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "import os\n",
    "os.chdir(\"../src\")\n",
    "\n",
    "from utils.conversation_utils import conversate, end_conversation\n",
    "from utils.conversation_utils import DEFAULT_SYSTEM_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is preparing your notebook to make requests to the OpenAI API by storing your API key in an environment variable. This key is crucial for authenticating and authorizing your access to the OpenAI services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT_TOKEN = \"<your-bot-token>\"\n",
    "OPENAI_API_KEY = \"<your-open-ai-api-key>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "bot = telebot.TeleBot(BOT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = {}\n",
    "prompts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=[\"start_ai\"])\n",
    "def open_conversation(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Respond to the commands with a welcome message.\n",
    "\n",
    "    Args:\n",
    "        message (telebot.types.Message): The message object representing the user's command.\n",
    "    \"\"\"\n",
    "    user_id = message.chat.id\n",
    "    end_conversation(user_id, conversations, prompts)\n",
    "    if len(message.text.split(\" \")) > 1:\n",
    "        system_prompt = message.text.split(\" \", 1)[1]\n",
    "    else:\n",
    "        system_prompt = DEFAULT_SYSTEM_PROMPT\n",
    "    prompts[user_id] = system_prompt\n",
    "    welcome_message = \"Hola, a partir de ahora estarás hablando con un bot inteligente con el siguiente contexto:\\n------\\n%s\\n------\\nEscribe mensaje para mantener una conversación\" %system_prompt\n",
    "    bot.reply_to(message, welcome_message)\n",
    "\n",
    "\n",
    "@bot.message_handler(commands=[\"end_ai\"])\n",
    "def close_conversation(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Respond to the commands with a goodbye message.\n",
    "\n",
    "    Args:\n",
    "        message (telebot.types.Message): The message object representing the user's command.\n",
    "    \"\"\"\n",
    "    user_id = message.chat.id\n",
    "    end_conversation(user_id, conversations, prompts)\n",
    "    goodbye_message = \"Ya no poseo inteligencia generativa, si quieres volver a añadirla, envía '/start_ai' ¡nos vemos pronto! 😉\"\n",
    "    bot.reply_to(message, goodbye_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`open_conversation` function:\n",
    "- Trigger: This function is triggered when a user sends the \"/start_ai\" command to the bot.\n",
    "- Purpose: It initializes a conversation with the user and sets up a context for an intelligent bot using OpenAI.\n",
    "- Key Actions:\n",
    "    - Ends any existing conversation for the user.\n",
    "    - Parses the system prompt from the command, or uses a default prompt.\n",
    "    - Stores the system prompt in a dictionary for the user.\n",
    "    - Sends a welcome message to the user with the context and prompts them to start the conversation.\n",
    "\n",
    "`close_conversation` function:\n",
    "- Trigger: This function is triggered when a user sends the \"/end_ai\" command to the bot.\n",
    "- Purpose: It concludes the conversation with the user and informs them that the bot no longer possesses generative intelligence.\n",
    "- Key Actions:\n",
    "    - Ends any existing conversation for the user.\n",
    "    - Sends a goodbye message to the user, encouraging them to restart the conversation if they want to re-enable generative intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(content_types=[\"text\"])\n",
    "def process_openai_step(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Process the message and respond using OpenAI\n",
    "\n",
    "    Args:\n",
    "        message (Message): The user's message.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        user_id = message.chat.id\n",
    "        message_text = message.text\n",
    "\n",
    "        reply_text = conversate(user_id, conversations, message_text, system_prompt=prompts.get(user_id))\n",
    "        msg = bot.reply_to(message, reply_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        bot.reply_to(message, f'Upsi, ha debido de haber algún problema')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`process_openai_step` function:\n",
    "- Trigger: This function is triggered when a user sends a text message to the bot.\n",
    "- Purpose: It processes the user's text message using OpenAI and responds accordingly.\n",
    "- Key Actions:\n",
    "    - Retrieves the user's ID and the text of their message.\n",
    "    - Utilizes the conversate function to generate a response based on the user's message and any existing conversation context.\n",
    "    - Sends the generated reply back to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.enable_save_next_step_handlers(delay=2)\n",
    "bot.load_next_step_handlers()\n",
    "bot.infinity_polling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Understanding why OpenAI + Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lines import necessary modules and classes from the LangChain library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up an instance of the ChatOpenAI class with the OpenAI's GPT-3.5-turbo model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo\"\n",
    "OPENAI_API_KEY = \"<your-open-ai-api-key>\"\n",
    "llm = ChatOpenAI(model_name=model_name, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **ChatOpenAI** to chat with OpenAI GPT. To do so, we'll define two type of messages:\n",
    "\n",
    "- SystemMessage: The system message sets the context for the assistant, it usually encapsulates the behavior of the agent\n",
    "- HumanMessage: Message from the user to interact with the model\n",
    "\n",
    "The output of the service will be a message from the assistant:\n",
    "- AIMessage: Message from the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that translates English to French.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Translate this sentence from English to French. I love programming.\"\n",
    "    ),\n",
    "]\n",
    "ai_message = llm(messages)\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's crucial to understand that GPT doesn't have memory. This means that each time you ask a question or send a message, it doesn't remember the previous conversation.\n",
    "\n",
    "So, if you send a new message or question to OpenAI, it won't have any knowledge of the previous answers or questions. The system treats each interaction as separate and doesn't retain information from one interaction to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [    \n",
    "    HumanMessage(\n",
    "        content=\"Translate again the previous sentence with other words\"\n",
    "    )\n",
    "]\n",
    "llm(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to provide the history of the conversation so that the new answer has all the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that translates English to French.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Translate this sentence from English to French. I love programming.\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=ai_message.content\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Translate again the previous sentence with other words\"\n",
    "    )\n",
    "]\n",
    "ai_message_2 = llm(messages)\n",
    "print(ai_message_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope you've enjoyed this demo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycones-demos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
